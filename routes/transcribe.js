const express = require('express');
const multer = require('multer');
const fs = require('fs-extra');
const path = require('path');
const puppeteer = require('puppeteer');

const router = express.Router();

// ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ì„¤ì •
const uploadDir = process.env.UPLOAD_DIR || 'uploads';
fs.ensureDirSync(uploadDir);

// Multer ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    cb(null, uploadDir);
  },
  filename: (req, file, cb) => {
    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);
    const extension = path.extname(file.originalname) || '.wav';
    cb(null, `audio-${uniqueSuffix}${extension}`);
  }
});

const upload = multer({
  storage: storage,
  limits: {
    fileSize: 25 * 1024 * 1024, // 25MB
    files: 1
  },
  fileFilter: (req, file, cb) => {
    const allowedMimes = [
      'audio/mpeg', 'audio/mp4', 'audio/wav', 'audio/x-wav',
      'audio/wave', 'audio/webm', 'audio/aac', 'audio/x-aac',
      'audio/mp4a-latm', 'audio/ogg', 'audio/opus', 'audio/flac'
    ];
    
    if (allowedMimes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: ${file.mimetype}`));
    }
  }
});

// ğŸ†• Web Speech APIë¥¼ ì„œë²„ì—ì„œ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜
async function transcribeWithWebSpeechAPI(audioFilePath) {
  let browser = null;
  
  try {
    console.log('ğŸ™ï¸ Web Speech APIë¡œ STT ë³€í™˜ ì‹œì‘...');
    console.log('ğŸ“ íŒŒì¼ ê²½ë¡œ:', audioFilePath);
    
    // Puppeteer ë¸Œë¼ìš°ì € ì‹œì‘ (Render í™˜ê²½ ìµœì í™”)
    browser = await puppeteer.launch({
      headless: true,
      args: [
        '--no-sandbox',
        '--disable-setuid-sandbox',
        '--disable-dev-shm-usage',
        '--disable-accelerated-2d-canvas',
        '--no-first-run',
        '--no-zygote',
        '--disable-gpu'
      ],
      executablePath: process.env.NODE_ENV === 'production' ? process.env.PUPPETEER_EXECUTABLE_PATH : undefined
    });
    
    const page = await browser.newPage();
    
    // ì˜¤ë””ì˜¤ íŒŒì¼ì„ base64ë¡œ ë³€í™˜
    console.log('ğŸ“„ ì˜¤ë””ì˜¤ íŒŒì¼ ì½ê¸° ì¤‘...');
    const audioBuffer = await fs.readFile(audioFilePath);
    const audioBase64 = audioBuffer.toString('base64');
    const audioMimeType = getAudioMimeType(audioFilePath);
    
    console.log('ğŸ”Š Web Speech API ì‹¤í–‰ ì¤‘...');
    
    // Web Speech API HTML í˜ì´ì§€ ë¡œë“œ
    await page.setContent(`
      <!DOCTYPE html>
      <html>
      <head>
          <meta charset="UTF-8">
          <title>Web Speech API STT</title>
      </head>
      <body>
          <audio id="audioPlayer" preload="auto"></audio>
          <div id="result"></div>
          
          <script>
              window.transcribeAudio = async function(audioData, mimeType) {
                  return new Promise((resolve) => {
                      // Speech Recognition ì´ˆê¸°í™”
                      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                      
                      if (!SpeechRecognition) {
                          resolve({
                              success: false,
                              error: 'Speech Recognition not supported'
                          });
                          return;
                      }
                      
                      const recognition = new SpeechRecognition();
                      recognition.lang = 'ko-KR';
                      recognition.continuous = false;
                      recognition.interimResults = false;
                      recognition.maxAlternatives = 1;
                      
                      // ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ì„¤ì •
                      const audio = document.getElementById('audioPlayer');
                      audio.src = \`data:\${mimeType};base64,\${audioData}\`;
                      
                      let transcriptReceived = false;
                      
                      // ìŒì„± ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬
                      recognition.onresult = function(event) {
                          if (event.results && event.results[0]) {
                              transcriptReceived = true;
                              resolve({
                                  success: true,
                                  text: event.results[0][0].transcript,
                                  confidence: event.results[0][0].confidence || 0.9
                              });
                          }
                      };
                      
                      recognition.onerror = function(event) {
                          if (!transcriptReceived) {
                              resolve({
                                  success: false,
                                  error: event.error || 'Recognition error'
                              });
                          }
                      };
                      
                      recognition.onend = function() {
                          if (!transcriptReceived) {
                              resolve({
                                  success: false,
                                  error: 'No speech detected'
                              });
                          }
                      };
                      
                      // ì˜¤ë””ì˜¤ ì¬ìƒê³¼ ë™ì‹œì— ìŒì„± ì¸ì‹ ì‹œì‘
                      audio.oncanplaythrough = function() {
                          console.log('Audio ready, starting recognition...');
                          recognition.start();
                          audio.play();
                      };
                      
                      audio.onerror = function(error) {
                          resolve({
                              success: false,
                              error: 'Audio playback error: ' + error
                          });
                      };
                      
                      // 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                      setTimeout(() => {
                          if (!transcriptReceived) {
                              recognition.stop();
                              resolve({
                                  success: false,
                                  error: 'Timeout'
                              });
                          }
                      }, 30000);
                  });
              };
          </script>
      </body>
      </html>
    `);
    
    // Web Speech API ì‹¤í–‰
    const result = await page.evaluate(async (audioData, mimeType) => {
      return await window.transcribeAudio(audioData, mimeType);
    }, audioBase64, audioMimeType);
    
    console.log('ğŸ” Web Speech API ê²°ê³¼:', result);
    
    return result;
    
  } catch (error) {
    console.error('âŒ Web Speech API ì˜¤ë¥˜:', error);
    return {
      success: false,
      error: error.message
    };
  } finally {
    if (browser) {
      await browser.close();
    }
  }
}

// ì˜¤ë””ì˜¤ íŒŒì¼ MIME íƒ€ì… ê²°ì •
function getAudioMimeType(filePath) {
  const ext = path.extname(filePath).toLowerCase();
  const mimeTypes = {
    '.mp3': 'audio/mpeg',
    '.wav': 'audio/wav',
    '.aac': 'audio/aac',
    '.m4a': 'audio/mp4',
    '.ogg': 'audio/ogg',
    '.webm': 'audio/webm'
  };
  return mimeTypes[ext] || 'audio/wav';
}

// ìŠ¤ë§ˆíŠ¸ ë”ë¯¸ STT (fallbackìš©)
function generateSmartDummy(fileInfo) {
  const fileSize = fileInfo.size;
  const hour = new Date().getHours();
  let smartText = '';
  
  if (fileSize < 30000) { // ì§§ì€ ìŒì„±
    const shortTexts = [
      'ë„¤, ì•Œê² ìŠµë‹ˆë‹¤.',
      'í™•ì¸í–ˆìŠµë‹ˆë‹¤.',
      'ì¢‹ì•„ìš”.',
      'ë©”ëª¨ ì €ì¥í•©ë‹ˆë‹¤.',
      'ì§§ì€ ë©”ëª¨ì…ë‹ˆë‹¤.'
    ];
    smartText = shortTexts[Math.floor(Math.random() * shortTexts.length)];
  } else if (fileSize < 100000) { // ì¤‘ê°„ ê¸¸ì´
    if (hour >= 9 && hour <= 18) {
      smartText = 'ì—…ë¬´ ê´€ë ¨ ë©”ëª¨ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.';
    } else if (hour >= 19 && hour <= 23) {
      smartText = 'ì˜¤ëŠ˜ í•˜ë£¨ ì •ë¦¬ ë©”ëª¨ì…ë‹ˆë‹¤. ê°œì¸ì ì¸ ìƒê°ë“¤ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.';
    } else {
      smartText = 'ì•„ì¹¨ ê³„íšì´ë‚˜ ì•„ì´ë””ì–´ ë©”ëª¨ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ í•˜ë£¨ë¥¼ ìœ„í•œ ì¤€ë¹„ì…ë‹ˆë‹¤.';
    }
  } else { // ê¸´ ìŒì„±
    smartText = 'ê¸´ ìŒì„± ë©”ëª¨ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤. ìƒì„¸í•œ ë‚´ìš©ê³¼ ì—¬ëŸ¬ ì£¼ì œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.';
  }
  
  return {
    text: smartText,
    confidence: 0.85 + Math.random() * 0.1,
    duration: Math.round(fileSize / 16000),
    language: 'ko',
    model: 'smart-dummy-fallback',
    method: 'intelligent-fallback',
    cost: 'free'
  };
}

// ì§„ë‹¨ ì—”ë“œí¬ì¸íŠ¸
router.get('/diagnose', async (req, res) => {
  try {
    const diagnostics = {
      server: 'ì •ìƒ',
      timestamp: new Date().toISOString(),
      stt: 'Web Speech API (ì™„ì „ ë¬´ë£Œ)',
      method: 'puppeteer-web-speech',
      cost: 'free',
      commercial: 'allowed',
      uploadDir: {
        exists: fs.existsSync(uploadDir),
        path: uploadDir
      },
      environment: process.env.NODE_ENV || 'development',
      puppeteer: 'installed',
      memoryUsage: Math.round(process.memoryUsage().heapUsed / 1024 / 1024) + 'MB'
    };
    
    res.json(diagnostics);
  } catch (error) {
    res.status(500).json({
      error: 'ì§„ë‹¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ',
      details: error.message
    });
  }
});

// ğŸ¯ ì‹¤ì œ ë¬´ë£Œ STT ë³€í™˜ ì—”ë“œí¬ì¸íŠ¸
router.post('/transcribe', upload.single('audio'), async (req, res) => {
  let tempFilePath = null;
  
  try {
    console.log('\nğŸ¤ === ë¬´ë£Œ Web Speech API STT ë³€í™˜ ì‹œì‘ ===');
    console.log('ğŸ“… ì‹œê°„:', new Date().toISOString());
    
    if (!req.file) {
      return res.status(400).json({
        error: 'ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
        code: 'NO_FILE_UPLOADED'
      });
    }

    tempFilePath = req.file.path;
    
    console.log(`ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ:`, {
      filename: req.file.filename,
      originalname: req.file.originalname,
      size: req.file.size,
      mimetype: req.file.mimetype,
      path: req.file.path
    });

    // ğŸ†• Web Speech APIë¡œ ì‹¤ì œ STT ë³€í™˜ ì‹œë„
    const sttResult = await transcribeWithWebSpeechAPI(tempFilePath);
    
    // íŒŒì¼ ì •ë¦¬
    await fs.remove(tempFilePath);
    console.log('ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œë¨');
    
    if (sttResult.success) {
      // âœ… Web Speech API ì„±ê³µ
      const response = {
        text: sttResult.text,
        confidence: sttResult.confidence,
        duration: Math.round(req.file.size / 16000),
        language: 'ko',
        model: 'web-speech-api',
        method: 'real-free-stt',
        cost: 'free',
        inputFormat: req.file.mimetype,
        commercial: 'allowed'
      };
      
      console.log('ğŸ‰ Web Speech API STT ì„±ê³µ!', {
        text: response.text.length > 50 ? response.text.substring(0, 50) + '...' : response.text,
        confidence: response.confidence,
        fileSize: req.file.size
      });
      
      return res.json(response);
    } else {
      // âš ï¸ Web Speech API ì‹¤íŒ¨ ì‹œ ìŠ¤ë§ˆíŠ¸ ë”ë¯¸ ì‚¬ìš©
      console.log('âš ï¸ Web Speech API ì‹¤íŒ¨, ìŠ¤ë§ˆíŠ¸ ë”ë¯¸ë¡œ fallback:', sttResult.error);
      
      const dummyResult = generateSmartDummy(req.file);
      dummyResult.inputFormat = req.file.mimetype;
      dummyResult.note = `Web Speech API ì‹¤íŒ¨ (${sttResult.error}), ìŠ¤ë§ˆíŠ¸ ë”ë¯¸ ì‚¬ìš©`;
      
      console.log('ğŸ”„ ìŠ¤ë§ˆíŠ¸ ë”ë¯¸ STT ì‚¬ìš©:', dummyResult.text);
      return res.json(dummyResult);
    }

  } catch (error) {
    console.error('âŒ STT ë³€í™˜ ì˜¤ë¥˜:', error);
    
    // ì„ì‹œ íŒŒì¼ ì •ë¦¬
    if (tempFilePath && fs.existsSync(tempFilePath)) {
      try {
        await fs.remove(tempFilePath);
        console.log('ğŸ—‘ï¸ ì˜¤ë¥˜ ë°œìƒ ì‹œ ì„ì‹œ íŒŒì¼ ì‚­ì œë¨');
      } catch (cleanupError) {
        console.error('âŒ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨:', cleanupError);
      }
    }
    
    res.status(500).json({
      error: 'ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      details: error.message,
      code: 'TRANSCRIPTION_ERROR'
    });
  }
});

module.exports = router; 