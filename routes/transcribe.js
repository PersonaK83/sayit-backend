const express = require('express');
const multer = require('multer');
const fs = require('fs-extra');
const path = require('path');
const { spawn } = require('child_process');

// âœ… Redis ëª¨ë“ˆ import ì¶”ê°€ (CRITICAL FIX!)
const redis = require('redis');

// âœ… ë¶„ì‚°ì²˜ë¦¬ë¥¼ ìœ„í•œ audio-processor import ì¶”ê°€
const { queueAudioTranscription, cleanupTempFiles } = require('../services/audio-processor');

const router = express.Router();

// âœ… ì‘ì—… ìƒíƒœ ê´€ë¦¬ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
const transcriptionJobs = new Map();

// ì‘ì—… ìƒíƒœ enum
const JobStatus = {
  PENDING: 'pending',
  PROCESSING: 'processing',
  COMPLETED: 'completed',
  FAILED: 'failed'
};

// ì‘ì—… ì •ë¦¬ (24ì‹œê°„ í›„ ìë™ ì‚­ì œ)
setInterval(() => {
  const now = Date.now();
  for (const [jobId, job] of transcriptionJobs.entries()) {
    if (now - job.createdAt > 24 * 60 * 60 * 1000) { // 24ì‹œê°„
      console.log(`ğŸ§¹ ë§Œë£Œëœ ì‘ì—… ì‚­ì œ: ${jobId}`);
      transcriptionJobs.delete(jobId);
    }
  }
}, 60 * 60 * 1000); // 1ì‹œê°„ë§ˆë‹¤ ì •ë¦¬

// ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ì„¤ì •
const uploadDir = process.env.UPLOAD_DIR || 'uploads';
fs.ensureDirSync(uploadDir);

// Multer ì„¤ì •
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    cb(null, uploadDir);
  },
  filename: (req, file, cb) => {
    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);
    const extension = path.extname(file.originalname) || '.wav';
    cb(null, `audio-${uniqueSuffix}${extension}`);
  }
});

const upload = multer({
  storage: storage,
  limits: {
    fileSize: 25 * 1024 * 1024, // 25MB
    files: 1
  },
  fileFilter: (req, file, cb) => {
    const allowedMimes = [
      'audio/mpeg', 'audio/mp4', 'audio/wav', 'audio/x-wav',
      'audio/wave', 'audio/webm', 'audio/aac', 'audio/x-aac',
      'audio/mp4a-latm', 'audio/ogg', 'audio/opus', 'audio/flac'
    ];

    if (allowedMimes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: ${file.mimetype}`));
    }
  }
});

// ë¡œì»¬ Whisper ì„¤ì¹˜ í™•ì¸
function checkWhisperInstallation() {
  return new Promise((resolve) => {
    const python = spawn('python3', ['-c', 'import whisper; print("installed")']);

    python.on('close', (code) => {
      resolve(code === 0);
    });

    python.on('error', () => {
      resolve(false);
    });
  });
}

// âœ… ë™ê¸° ì „ìš© Whisper ë³€í™˜ (ë¶„ì‚°ì²˜ë¦¬ ì•ˆ í•¨)
async function transcribeWithLocalWhisperSync(audioFilePath, jobId, language = 'auto') {
  return new Promise((resolve) => {
    console.log(`ğŸ™ï¸ ë™ê¸° Whisper ë³€í™˜ ì‹œì‘ [${jobId}]...`);
    console.log('ğŸ“ íŒŒì¼ ê²½ë¡œ:', audioFilePath);
    console.log('ğŸŒ ì–¸ì–´ ì„¤ì •:', language);

    // ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸: ì²˜ë¦¬ ì¤‘
    const job = transcriptionJobs.get(jobId);
    if (job) {
      job.status = JobStatus.PROCESSING;
      job.startedAt = Date.now();
      transcriptionJobs.set(jobId, job);
    }

    // Whisper ëª…ë ¹ì–´ êµ¬ì„±
    const whisperArgs = [
      audioFilePath,
      '--model', 'base',
      '--output_dir', path.dirname(audioFilePath),
      '--output_format', 'txt'
    ];

    if (language !== 'auto') {
      whisperArgs.push('--language', language);
    }

    console.log('ğŸ”§ Whisper ëª…ë ¹ì–´:', 'whisper', whisperArgs.join(' '));

    const whisper = spawn('whisper', whisperArgs);

    let stdout = '';
    let stderr = '';

    whisper.stdout.on('data', (data) => {
      stdout += data.toString();
      console.log(`ğŸ“Š Whisper ì¶œë ¥: ${data.toString().trim()}`);
    });

    whisper.stderr.on('data', (data) => {
      stderr += data.toString();
      console.log(`âš ï¸ Whisper ê²½ê³ : ${data.toString().trim()}`);
    });

    whisper.on('close', async (code) => {
      console.log(`ğŸ¯ Whisper ë³€í™˜ ì™„ë£Œ [${jobId}], ì¢…ë£Œ ì½”ë“œ: ${code}`);

      if (code === 0) {
        try {
          // ê²°ê³¼ íŒŒì¼ ì½ê¸°
          const outputFile = audioFilePath.replace(/\.[^/.]+$/, '.txt');
          const transcript = await fs.readFile(outputFile, 'utf8');

          // ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸: ì™„ë£Œ
          if (job) {
            job.status = JobStatus.COMPLETED;
            job.completedAt = Date.now();
            job.transcript = transcript.trim();
            job.error = null;
            transcriptionJobs.set(jobId, job);
          }

          console.log(`âœ… ë™ê¸° ë³€í™˜ ì„±ê³µ [${jobId}]: ${transcript.trim().length}ì`);
          resolve({ success: true, transcript: transcript.trim() });

        } catch (readError) {
          console.error(`âŒ ê²°ê³¼ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ [${jobId}]:`, readError);
          
          if (job) {
            job.status = JobStatus.FAILED;
            job.completedAt = Date.now();
            job.error = 'ê²°ê³¼ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨';
            transcriptionJobs.set(jobId, job);
          }
          
          resolve({ success: false, error: 'ê²°ê³¼ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨' });
        }
      } else {
        console.error(`âŒ Whisper ë³€í™˜ ì‹¤íŒ¨ [${jobId}], ì¢…ë£Œ ì½”ë“œ: ${code}`);
        console.error('stderr:', stderr);
        
        if (job) {
          job.status = JobStatus.FAILED;
          job.completedAt = Date.now();
          job.error = `Whisper ë³€í™˜ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code})`;
          transcriptionJobs.set(jobId, job);
        }
        
        resolve({ success: false, error: `Whisper ë³€í™˜ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code})` });
      }
    });

    whisper.on('error', (error) => {
      console.error(`âŒ Whisper ì‹¤í–‰ ì˜¤ë¥˜ [${jobId}]:`, error);
      
      if (job) {
        job.status = JobStatus.FAILED;
        job.completedAt = Date.now();
        job.error = `Whisper ì‹¤í–‰ ì˜¤ë¥˜: ${error.message}`;
        transcriptionJobs.set(jobId, job);
      }
      
      resolve({ success: false, error: `Whisper ì‹¤í–‰ ì˜¤ë¥˜: ${error.message}` });
    });
  });
}

// íŒŒì¼ í¬ê¸° ê¸°ë°˜ ì˜ˆìƒ ì‹œê°„ ê³„ì‚° (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
function estimateDurationFromSize(fileSizeKB) {
  // ì‹¤ì œ ì¸¡ì •: 2.1KB/ì´ˆ
  const ACTUAL_RATIO = 2.1; // KB per second
  return Math.ceil(fileSizeKB / ACTUAL_RATIO);
}

// ë™ì  ì²­í¬ í¬ê¸° ê³„ì‚° (audio-processor.jsì™€ ë™ì¼)
function calculateOptimalChunkDuration(estimatedDurationSeconds) {
  console.log(`ğŸ“Š ì˜ˆìƒ íŒŒì¼ ê¸¸ì´: ${estimatedDurationSeconds}ì´ˆ (${(estimatedDurationSeconds/60).toFixed(1)}ë¶„)`);
  
  if (estimatedDurationSeconds <= 60) {        // 1ë¶„ ì´í•˜
    console.log(`ğŸ¯ ì²­í¬ ì „ëµ: ì§§ì€ íŒŒì¼ - 30ì´ˆ ì²­í¬`);
    return 30;  // 30ì´ˆ ì²­í¬ (2ê°œ ì²­í¬)
  } else if (estimatedDurationSeconds <= 300) { // 5ë¶„ ì´í•˜ âœ…
    console.log(`ğŸ¯ ì²­í¬ ì „ëµ: ë³´í†µ íŒŒì¼ - 60ì´ˆ ì²­í¬`);
    return 60;  // 1ë¶„ ì²­í¬ (5ê°œ ì²­í¬) âœ…
  } else if (estimatedDurationSeconds <= 900) { // 15ë¶„ ì´í•˜ âœ…
    console.log(`ğŸ¯ ì²­í¬ ì „ëµ: ê¸´ íŒŒì¼ - 90ì´ˆ ì²­í¬`);
    return 90;  // 1.5ë¶„ ì²­í¬ (10ê°œ ì²­í¬)
  } else if (estimatedDurationSeconds <= 1800) { // 30ë¶„ ì´í•˜ âœ… NEW!
    console.log(`ğŸ¯ ì²­í¬ ì „ëµ: ë§¤ìš° ê¸´ íŒŒì¼ - 120ì´ˆ ì²­í¬`);
    return 120; // 2ë¶„ ì²­í¬ (15ê°œ ì²­í¬) âœ…
  } else {                                      // 30ë¶„ ì´ˆê³¼ âœ… NEW!
    console.log(`ğŸ¯ ì²­í¬ ì „ëµ: ì´ˆì¥ì‹œê°„ íŒŒì¼ - 180ì´ˆ ì²­í¬`);
    return 180; // 3ë¶„ ì²­í¬
  }
}

// âœ… 30ë¶„ ëŒ€ì‘: ì²­í¬ ìˆ˜ ì œí•œ í•´ì œ
function estimateChunkCount(fileSize) {
  const fileSizeKB = fileSize / 1024;
  const estimatedDurationSeconds = estimateDurationFromSize(fileSizeKB);
  const chunkDurationSeconds = calculateOptimalChunkDuration(estimatedDurationSeconds);
  
  const estimatedChunks = Math.ceil(estimatedDurationSeconds / chunkDurationSeconds);
  
  // âœ… 30ë¶„ ëŒ€ì‘: ìµœëŒ€ ì œí•œì„ 10ê°œ â†’ 30ê°œë¡œ í™•ì¥
  const maxChunks = 30; // ìµœëŒ€ 30ê°œ ì²­í¬ (30ë¶„ Ã— 2ë¶„ì²­í¬ = 15ê°œ ì—¬ìœ )
  const finalChunks = Math.max(1, Math.min(maxChunks, estimatedChunks));
  
  console.log(`ğŸ“Š ì²­í¬ ê³„ì‚°: ${estimatedDurationSeconds}ì´ˆ â†’ ${chunkDurationSeconds}ì´ˆ ì²­í¬ â†’ ${estimatedChunks}ê°œ â†’ ì œí•œì ìš© ${finalChunks}ê°œ`);
  
  return finalChunks;
}

// âœ… 30ë¶„ ëŒ€ì‘: íŒŒì¼ í¬ê¸° ê¸°ì¤€ ì¡°ì •
function shouldUseAsyncProcessing(fileSizeKB) {
  // 65KB ê¸°ì¤€ (ì•½ 30ì´ˆ) â†’ 30ë¶„ ëŒ€ì‘ì„ ìœ„í•´ ìœ ì§€
  return fileSizeKB > 65;
}

// âœ… 30ë¶„ ëŒ€ì‘: Redis í´ë§ ë¡œì§ ê°œì„ 
async function checkRedisResults() {
  try {
    console.log('ğŸ” [Direct-Backend] Redis í´ë§ ì‹¤í–‰ ì¤‘...');
    
    const redisClient = redis.createClient({
      url: 'redis://sayit-redis-m2:6379'
    });
    
    await redisClient.connect();
    
    // âœ… ì™„ë£Œëœ ì²­í¬ì™€ ì‹¤íŒ¨í•œ ì²­í¬ ëª¨ë‘ í™•ì¸
    const completedKeys = await redisClient.keys('completed:*:chunk:*');
    const failedKeys = await redisClient.keys('failed:*:chunk:*');
    
    console.log(`ğŸ“‹ [Direct-Backend] Redis í˜„í™©: ì™„ë£Œ ${completedKeys.length}ê°œ, ì‹¤íŒ¨ ${failedKeys.length}ê°œ`);
    
    // JobIdë³„ë¡œ ì²­í¬ë“¤ì„ ê·¸ë£¹í™”
    const jobChunks = {};
    const failedChunks = {};
    
    // ì™„ë£Œëœ ì²­í¬ë“¤ ì²˜ë¦¬
    for (const key of completedKeys) {
      try {
        const resultData = await redisClient.get(key);
        if (resultData) {
          const data = JSON.parse(resultData);
          const { jobId, chunkIndex, result, processedBy, workerMode } = data;
          
          console.log(`ğŸ“¦ [Direct-Backend] ì™„ë£Œ ì²­í¬: ${jobId} ì²­í¬ ${chunkIndex} (ì²˜ë¦¬ì: ${processedBy})`);
          
          if (!jobChunks[jobId]) {
            jobChunks[jobId] = [];
          }
          
          jobChunks[jobId].push({
            chunkIndex,
            result,
            processedBy,
            workerMode,
            key
          });
        }
      } catch (parseError) {
        console.error('âŒ [Direct-Backend] Redis ì™„ë£Œ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨:', parseError);
      }
    }
    
    // âœ… ì‹¤íŒ¨í•œ ì²­í¬ë“¤ ì²˜ë¦¬ (NEW!)
    for (const key of failedKeys) {
      try {
        const failedData = await redisClient.get(key);
        if (failedData) {
          const data = JSON.parse(failedData);
          const { jobId, chunkIndex, errorMessage, failedBy } = data;
          
          console.log(`ğŸ’¥ [Direct-Backend] ì‹¤íŒ¨ ì²­í¬: ${jobId} ì²­í¬ ${chunkIndex} (ì‹¤íŒ¨ì: ${failedBy}) - ${errorMessage}`);
          
          if (!failedChunks[jobId]) {
            failedChunks[jobId] = [];
          }
          
          failedChunks[jobId].push({
            chunkIndex,
            errorMessage,
            failedBy,
            key
          });
        }
      } catch (parseError) {
        console.error('âŒ [Direct-Backend] Redis ì‹¤íŒ¨ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨:', parseError);
      }
    }
    
    // ì™„ë£Œëœ ì‘ì—…ë“¤ ì²˜ë¦¬
    for (const [jobId, chunks] of Object.entries(jobChunks)) {
      const job = transcriptionJobs.get(jobId);
      if (job && job.status === JobStatus.PROCESSING) {
        
        // âœ… ì‹¤íŒ¨í•œ ì²­í¬ë„ ê³ ë ¤í•œ ì™„ë£Œ í™•ì¸
        const failedChunksForJob = failedChunks[jobId] || [];
        const totalProcessedChunks = chunks.length + failedChunksForJob.length;
        
        console.log(`ğŸ” [Direct-Backend] ì‘ì—… [${jobId}] ì²­í¬ ìƒíƒœ í™•ì¸:`);
        console.log(`   ğŸ“Š ì™„ë£Œëœ ì²­í¬: ${chunks.length}ê°œ`);
        console.log(`   ğŸ’¥ ì‹¤íŒ¨í•œ ì²­í¬: ${failedChunksForJob.length}ê°œ`);
        console.log(`   ğŸ“Š ì´ ì²˜ë¦¬ëœ ì²­í¬: ${totalProcessedChunks}ê°œ`);
        
        // ì˜ˆìƒ ì²­í¬ ìˆ˜ í™•ì¸
        const expectedChunks = job.expectedChunks || estimateChunkCount(job.fileSize);
        console.log(`   ğŸ“Š ì˜ˆìƒ ì²­í¬ ìˆ˜: ${expectedChunks}ê°œ`);
        
        // âœ… 30ë¶„ ëŒ€ì‘: ëª¨ë“  ì²­í¬ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸ (ì‹¤íŒ¨ í¬í•¨)
        if (totalProcessedChunks >= expectedChunks) {
          console.log(`ğŸ¯ [Direct-Backend] ëª¨ë“  ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ! ì·¨í•© ì‹œì‘ [${jobId}]`);
          
          // ì²­í¬ë¥¼ ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ ì •ë ¬
          const sortedChunks = chunks.sort((a, b) => a.chunkIndex - b.chunkIndex);
          
          // âœ… ì‹¤íŒ¨í•œ ì²­í¬ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬ (ì—°ì†ì„± ë³´ì¥)
          const allChunks = [];
          for (let i = 0; i < expectedChunks; i++) {
            const chunk = sortedChunks.find(c => c.chunkIndex === i);
            if (chunk) {
              allChunks.push(chunk.result || '');
            } else {
              // ì‹¤íŒ¨í•œ ì²­í¬ í™•ì¸
              const failedChunk = failedChunksForJob.find(f => f.chunkIndex === i);
              if (failedChunk) {
                console.warn(`âš ï¸ [Direct-Backend] ì²­í¬ ${i} ì‹¤íŒ¨ë¡œ ì¸í•œ ë¹ˆ êµ¬ê°„: ${failedChunk.errorMessage}`);
                allChunks.push(''); // ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
              } else {
                console.warn(`âš ï¸ [Direct-Backend] ì²­í¬ ${i} ëˆ„ë½ë¨`);
                allChunks.push('');
              }
            }
          }
          
          // ëª¨ë“  ì²­í¬ ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ê²°í•© (ë¹ˆ êµ¬ê°„ ì œì™¸)
          const finalResult = allChunks.filter(chunk => chunk.trim() !== '').join(' ');
          
          // ì²˜ë¦¬í•œ ì»¨í…Œì´ë„ˆ ëª©ë¡
          const processedByList = [...new Set(sortedChunks.map(chunk => chunk.processedBy))];
          const successRate = (sortedChunks.length / expectedChunks * 100).toFixed(1);
          
          job.status = JobStatus.COMPLETED;
          job.completedAt = Date.now();
          job.transcript = finalResult;
          job.error = failedChunksForJob.length > 0 ? `ì¼ë¶€ ì²­í¬ ì‹¤íŒ¨ (${failedChunksForJob.length}/${expectedChunks}ê°œ)` : null;
          job.successRate = successRate;
          transcriptionJobs.set(jobId, job);
          
          console.log(`âœ… [Direct-Backend] ì‘ì—… ì™„ë£Œ ì²˜ë¦¬ [${jobId}]`);
          console.log(`ğŸ“ [Direct-Backend] ìµœì¢… ê²°ê³¼: ${finalResult.substring(0, 100)}... (${finalResult.length}ì)`);
          console.log(`ğŸ·ï¸ [Direct-Backend] ì²˜ë¦¬ ì»¨í…Œì´ë„ˆë“¤: ${processedByList.join(', ')}`);
          console.log(`ğŸ“Š [Direct-Backend] ì„±ê³µë¥ : ${successRate}% (${sortedChunks.length}/${expectedChunks})`);
          
          // âœ… ì²˜ë¦¬ëœ í‚¤ë“¤ê³¼ ì‹¤íŒ¨ í‚¤ë“¤ ëª¨ë‘ ì‚­ì œ
          for (const chunk of chunks) {
            await redisClient.del(chunk.key);
          }
          for (const failed of failedChunksForJob) {
            await redisClient.del(failed.key);
          }
          
        } else {
          console.log(`â³ [Direct-Backend] ì‘ì—… [${jobId}] ëŒ€ê¸° ì¤‘: ${totalProcessedChunks}/${expectedChunks} ì²­í¬ ì²˜ë¦¬ë¨`);
          
          // âœ… ìƒì„¸í•œ ì§„í–‰ ìƒí™© ì¶œë ¥
          const completedIndices = chunks.map(c => c.chunkIndex).sort((a, b) => a - b);
          const failedIndices = failedChunksForJob.map(f => f.chunkIndex).sort((a, b) => a - b);
          const allIndices = Array.from({length: expectedChunks}, (_, i) => i);
          const pendingIndices = allIndices.filter(i => 
            !completedIndices.includes(i) && !failedIndices.includes(i)
          );
          
          console.log(`   ğŸ“‹ ì™„ë£Œëœ ì²­í¬: [${completedIndices.join(', ')}]`);
          if (failedIndices.length > 0) {
            console.log(`   ğŸ’¥ ì‹¤íŒ¨í•œ ì²­í¬: [${failedIndices.join(', ')}]`);
          }
          console.log(`   â³ ëŒ€ê¸° ì¤‘ì¸ ì²­í¬: [${pendingIndices.join(', ')}]`);
          
          // âœ… 30ë¶„ ëŒ€ì‘: ì¥ì‹œê°„ ëŒ€ê¸° ì‹œ íƒ€ì„ì•„ì›ƒ ì²´í¬
          const jobAge = Date.now() - job.createdAt;
          if (jobAge > 600000) { // 10ë¶„ ì´ˆê³¼ ëŒ€ê¸°
            console.warn(`âš ï¸ [Direct-Backend] ì‘ì—… [${jobId}] ì¥ì‹œê°„ ëŒ€ê¸° (${Math.floor(jobAge/60000)}ë¶„)`);
          }
        }
      }
    }
    
    await redisClient.quit();
    
  } catch (error) {
    console.error('âŒ [Direct-Backend] Redis ê²°ê³¼ í™•ì¸ ì‹¤íŒ¨:', error);
  }
}

// âœ… 30ë¶„ ëŒ€ì‘: í´ë§ ê°„ê²© ìµœì í™” (5ì´ˆ â†’ 3ì´ˆ)
setInterval(checkRedisResults, 3000);
console.log('âœ… Redis í´ë§ ì‹œìŠ¤í…œ ì‹œì‘ (3ì´ˆ ê°„ê²©)');

// âœ… ê°œë³„ ì‘ì—… ì²˜ë¦¬ í•¨ìˆ˜ (íŒŒì¼ ì •ë¦¬ ì¶”ê°€)
async function processJobChunks(jobId, chunks, redisClient) {
  try {
    const job = transcriptionJobs.get(jobId);
    
    // âœ… ì´ë¯¸ ì™„ë£Œëœ ì‘ì—…ì€ ê±´ë„ˆë›°ê¸° (ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€)
    if (!job || job.status !== JobStatus.PROCESSING) {
      console.log(`â­ï¸ [Direct-Backend] ì‘ì—… [${jobId}] ê±´ë„ˆë›°ê¸°: ${job ? job.status : 'ì‘ì—… ì—†ìŒ'}`);
      return;
    }
    
    console.log(`ğŸ” [Direct-Backend] ì‘ì—… [${jobId}] ì²­í¬ ìƒíƒœ í™•ì¸:`);
    console.log(`   ğŸ“Š ì™„ë£Œëœ ì²­í¬: ${chunks.length}ê°œ`);
    
    // ì˜ˆìƒ ì²­í¬ ìˆ˜ í™•ì¸
    const expectedChunks = job.expectedChunks || estimateChunkCount(job.fileSize);
    console.log(`   ğŸ“Š ì˜ˆìƒ ì²­í¬ ìˆ˜: ${expectedChunks}ê°œ`);
    
    // âœ… ì¤‘ë³µ ì²­í¬ ì œê±°
    const uniqueChunks = [];
    const seenIndices = new Set();
    
    for (const chunk of chunks) {
      if (!seenIndices.has(chunk.chunkIndex)) {
        uniqueChunks.push(chunk);
        seenIndices.add(chunk.chunkIndex);
      } else {
        console.log(`âš ï¸ [Direct-Backend] ì¤‘ë³µ ì²­í¬ ë°œê²¬: ${jobId} ì²­í¬ ${chunk.chunkIndex}`);
      }
    }
    
    console.log(`   ğŸ“Š ê³ ìœ  ì²­í¬: ${uniqueChunks.length}ê°œ`);
    
    // âœ… ëª¨ë“  ì²­í¬ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
    if (uniqueChunks.length >= expectedChunks) {
      console.log(`ğŸ¯ [Direct-Backend] ëª¨ë“  ì²­í¬ ì™„ë£Œ! ì·¨í•© ì‹œì‘ [${jobId}]`);
      
      // âœ… ì›ìì  ì‘ì—… ìƒíƒœ ë³€ê²½ (Race Condition ë°©ì§€)
      if (job.status !== JobStatus.PROCESSING) {
        console.log(`âš ï¸ [Direct-Backend] ì‘ì—… [${jobId}] ì´ë¯¸ ì²˜ë¦¬ë¨: ${job.status}`);
        return;
      }
      
      // ì²­í¬ë¥¼ ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ ì •ë ¬
      const sortedChunks = uniqueChunks.sort((a, b) => a.chunkIndex - b.chunkIndex);
      
      // ëª¨ë“  ì²­í¬ ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ê²°í•©
      const finalResult = sortedChunks.map(chunk => chunk.result).join(' ');
      
      // ì²˜ë¦¬í•œ ì»¨í…Œì´ë„ˆ ëª©ë¡
      const processedByList = [...new Set(sortedChunks.map(chunk => chunk.processedBy))];
      
      // âœ… ì›ìì  ìƒíƒœ ì—…ë°ì´íŠ¸
      job.status = JobStatus.COMPLETED;
      job.completedAt = Date.now();
      job.transcript = finalResult;
      job.error = null;
      transcriptionJobs.set(jobId, job);
      
      console.log(`âœ… [Direct-Backend] ì‘ì—… ì™„ë£Œ ì²˜ë¦¬ [${jobId}]`);
      console.log(`ğŸ“ [Direct-Backend] ìµœì¢… ê²°ê³¼: ${finalResult.substring(0, 100)}...`);
      console.log(`ğŸ·ï¸ [Direct-Backend] ì²˜ë¦¬ ì»¨í…Œì´ë„ˆë“¤: ${processedByList.join(', ')}`);
      console.log(`ğŸ“Š [Direct-Backend] ì²­í¬ë³„ ì²˜ë¦¬ì:`);
      
      sortedChunks.forEach((chunk) => {
        console.log(`   ì²­í¬ ${chunk.chunkIndex}: ${chunk.processedBy}`);
      });
      
      // âœ… ì²˜ë¦¬ëœ í‚¤ë“¤ ì•ˆì „í•˜ê²Œ ì‚­ì œ
      const deletedKeys = [];
      for (const chunk of chunks) {
        try {
          const deleted = await redisClient.del(chunk.key);
          if (deleted) {
            deletedKeys.push(chunk.key);
          }
        } catch (delError) {
          console.error(`âŒ [Direct-Backend] í‚¤ ì‚­ì œ ì‹¤íŒ¨: ${chunk.key}`, delError);
        }
      }
      
      console.log(`ğŸ—‘ï¸ [Direct-Backend] ì‚­ì œëœ í‚¤: ${deletedKeys.length}ê°œ`);
      
      // âœ… ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ë¹„ë™ê¸°ë¡œ ì‹¤í–‰)
      setTimeout(async () => {
        try {
          const tempDir = `/app/temp/${jobId}`;
          await cleanupTempFiles(tempDir);
          console.log(`ğŸ§¹ [Direct-Backend] ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ [${jobId}]`);
        } catch (cleanupError) {
          console.error(`âŒ [Direct-Backend] ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨ [${jobId}]:`, cleanupError);
        }
      }, 5000); // 5ì´ˆ í›„ ì •ë¦¬ (ê²°ê³¼ ì „ì†¡ í›„)
      
    } else {
      console.log(`â³ [Direct-Backend] ì‘ì—… [${jobId}] ëŒ€ê¸° ì¤‘: ${uniqueChunks.length}/${expectedChunks} ì²­í¬ ì™„ë£Œ`);
      
      // ì™„ë£Œëœ ì²­í¬ ëª©ë¡ ì¶œë ¥
      const completedIndices = uniqueChunks.map(c => c.chunkIndex).sort((a, b) => a - b);
      console.log(`   ğŸ“‹ ì™„ë£Œëœ ì²­í¬: [${completedIndices.join(', ')}]`);
      
      // ëŒ€ê¸° ì¤‘ì¸ ì²­í¬ ëª©ë¡
      const allIndices = Array.from({length: expectedChunks}, (_, i) => i);
      const pendingIndices = allIndices.filter(i => !completedIndices.includes(i));
      console.log(`   â³ ëŒ€ê¸° ì¤‘ì¸ ì²­í¬: [${pendingIndices.join(', ')}]`);
    }
    
  } catch (error) {
    console.error(`âŒ [Direct-Backend] ì‘ì—… [${jobId}] ì²˜ë¦¬ ì‹¤íŒ¨:`, error);
  }
}

// âœ… ì—…ë¡œë“œ íŒŒì¼ ì •ë¦¬ í•¨ìˆ˜
async function cleanupUploadFile(filePath) {
  try {
    console.log(`ğŸ§¹ [Direct-Backend] ì—…ë¡œë“œ íŒŒì¼ ì •ë¦¬: ${filePath}`);
    await fs.unlink(filePath);
    console.log(`âœ… [Direct-Backend] ì—…ë¡œë“œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: ${filePath}`);
  } catch (error) {
    console.error(`âŒ [Direct-Backend] ì—…ë¡œë“œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: ${filePath}`, error);
  }
}

// API ë¼ìš°íŠ¸ë“¤
router.post('/transcribe', upload.single('audio'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'ì˜¤ë””ì˜¤ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.' });
    }

    const audioFilePath = req.file.path;
    const originalFilename = req.file.originalname;
    const fileSize = req.file.size;
    const language = req.body.language || 'auto';
    
    // ğŸ”§ íŒŒì¼ í¬ê¸° ê¸°ë°˜ ìë™ íŒë‹¨ ë¡œì§
    const fileSizeKB = fileSize / 1024;
    const estimatedDuration = estimateDurationFromSize(fileSizeKB);

    // ì‘ì—… ID ìƒì„±
    const jobId = `job_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

    // 30ì´ˆ ê¸°ì¤€ìœ¼ë¡œ ë™ê¸°/ë¹„ë™ê¸° ê²°ì •
    const shouldUseAsync = estimatedDuration > 30 || req.body.async === 'true';

    if (shouldUseAsync) {
      // ë¹„ë™ê¸° ì²˜ë¦¬ ë¡œì§
      console.log(`ğŸ”„ ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œì‘ [${jobId}] - ì˜ˆìƒ ${estimatedDuration}ì´ˆ`);
    } else {
      // ë™ê¸° ì²˜ë¦¬ ë¡œì§
      console.log(`âš¡ ë™ê¸° ì²˜ë¦¬ ì‹œì‘ [${jobId}] - ì˜ˆìƒ ${estimatedDuration}ì´ˆ`);
    }

    // Whisper ì„¤ì¹˜ í™•ì¸
    const whisperInstalled = await checkWhisperInstallation();
    if (!whisperInstalled) {
      return res.status(500).json({ 
        error: 'Whisperê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
        recommendation: 'pip3 install openai-whisper ëª…ë ¹ì–´ë¡œ Whisperë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.'
      });
    }

    

    if (shouldUseAsync) {
      // ğŸ”§ ë¶„ì‚°ì²˜ë¦¬ (í ì‹œìŠ¤í…œ ì‚¬ìš©)
      console.log(`ğŸ”„ ë¶„ì‚°ì²˜ë¦¬ ì‹œì‘ [${jobId}]`);
      
      // ì‘ì—… ë“±ë¡
      const job = {
        id: jobId,
        status: JobStatus.PENDING,
        originalFilename,
        fileSize,
        language,
        createdAt: Date.now(),
        startedAt: null,
        completedAt: null,
        transcript: null,
        error: null,
        expectedChunks: null,
        uploadFilePath: audioFilePath // âœ… ì—…ë¡œë“œ íŒŒì¼ ê²½ë¡œ ì €ì¥
      };

      transcriptionJobs.set(jobId, job);
      console.log(`ğŸ“ ì‘ì—… ë“±ë¡ ì™„ë£Œ [${jobId}]: ${originalFilename}`);
      
      // âœ… ë¶„ì‚°ì²˜ë¦¬: íì— ë“±ë¡ (JobId ì „ë‹¬)
      try {
        console.log(`ğŸ“¤ í ë“±ë¡ ì‹œì‘ [${jobId}]`);
        const queueResult = await queueAudioTranscription(audioFilePath, jobId, language);
        console.log(`ğŸ“¤ í ë“±ë¡ ì™„ë£Œ [${jobId}] - Workerë“¤ì´ ì²˜ë¦¬ ì‹œì‘`);
        
        // âœ… ì‹¤ì œ ì²­í¬ ìˆ˜ë¥¼ ì‘ì—…ì— ì €ì¥
        job.expectedChunks = queueResult.chunkCount;
        job.status = JobStatus.PROCESSING;
        job.startedAt = Date.now();
        transcriptionJobs.set(jobId, job);
        
        console.log(`ğŸ“Š [Direct-Backend] ì˜ˆìƒ ì²­í¬ ìˆ˜: ${queueResult.chunkCount}ê°œ`);
        
        // âœ… ì—…ë¡œë“œ íŒŒì¼ ì •ë¦¬ ì˜ˆì•½ (30ë¶„ í›„)
        setTimeout(async () => {
          await cleanupUploadFile(audioFilePath);
        }, 30 * 60 * 1000); // 30ë¶„ í›„
        
      } catch (error) {
        console.error(`âŒ í ë“±ë¡ ì‹¤íŒ¨ [${jobId}]:`, error);
        job.status = JobStatus.FAILED;
        job.error = 'í ë“±ë¡ ì‹¤íŒ¨';
        transcriptionJobs.set(jobId, job);
        
        // âœ… ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì—…ë¡œë“œ íŒŒì¼ ì •ë¦¬
        setTimeout(async () => {
          await cleanupUploadFile(audioFilePath);
        }, 5000); // 5ì´ˆ í›„
      }
      
      // ì¦‰ì‹œ ì‘ë‹µ (JobID + processing ìƒíƒœ)
      res.json({
        jobId,
        status: 'processing',
        message: 'ìŒì„± ë³€í™˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.',
        originalFilename,
        fileSize,
        reason: shouldUseAsync ? 'íŒŒì¼ í¬ê¸°ë¡œ ì¸í•œ ìë™ ë¶„ì‚°ì²˜ë¦¬' : 'ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¥¸ ë¶„ì‚°ì²˜ë¦¬'
      });
      
    } else {
      // ğŸ”§ ë™ê¸° ì²˜ë¦¬ (Direct Backendì—ì„œ ì§ì ‘ ì²˜ë¦¬)
      console.log(`âš¡ ë™ê¸° ì²˜ë¦¬ ì‹œì‘ [${jobId}]`);
      
      // ì‘ì—… ë“±ë¡ (ë™ê¸° ì²˜ë¦¬ìš©)
      const job = {
        id: jobId,
        status: JobStatus.PROCESSING,
        originalFilename,
        fileSize,
        language,
        createdAt: Date.now(),
        startedAt: Date.now(),
        completedAt: null,
        transcript: null,
        error: null
      };

      transcriptionJobs.set(jobId, job);
      console.log(`ğŸ“ ì‘ì—… ë“±ë¡ ì™„ë£Œ [${jobId}]: ${originalFilename}`);
      
      // ë™ê¸°ì ìœ¼ë¡œ ë³€í™˜ ì‹¤í–‰ (await ì‚¬ìš©)
      const result = await transcribeWithLocalWhisperSync(audioFilePath, jobId, language);
      
      if (result.success) {
        // ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸
        job.status = JobStatus.COMPLETED;
        job.completedAt = Date.now();
        job.transcript = result.transcript;
        transcriptionJobs.set(jobId, job);
        
        console.log(`âœ… ë™ê¸° ë³€í™˜ ì™„ë£Œ [${jobId}]: ${result.transcript.length}ì`);
        
        // âœ… ë™ê¸° ì²˜ë¦¬ ì‘ë‹µ: jobId ì œê±°í•˜ê³  success ì¶”ê°€
        res.json({
          success: true,
          status: 'completed',
          transcript: result.transcript,
          originalFilename,
          fileSize,
          processingTime: Date.now() - job.startedAt
        });
      } else {
        // ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸
        job.status = JobStatus.FAILED;
        job.completedAt = Date.now();
        job.error = result.error;
        transcriptionJobs.set(jobId, job);
        
        console.log(`âŒ ë™ê¸° ë³€í™˜ ì‹¤íŒ¨ [${jobId}]: ${result.error}`);
        
        // âœ… ë™ê¸° ì²˜ë¦¬ ì‹¤íŒ¨ ì‘ë‹µ: jobId ì œê±°í•˜ê³  success ì¶”ê°€
        res.status(500).json({
          success: false,
          status: 'failed',
          error: result.error,
          originalFilename,
          fileSize
        });
      }

      // âœ… ë™ê¸° ì²˜ë¦¬ ì™„ë£Œ í›„ íŒŒì¼ ì •ë¦¬
      setTimeout(async () => {
        await cleanupUploadFile(audioFilePath);
      }, 10000); // 10ì´ˆ í›„
    }

  } catch (error) {
    console.error('âŒ ë³€í™˜ ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
    res.status(500).json({ error: 'ë³€í™˜ ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨' });
  }
});

// âœ… ì‘ì—… ìƒíƒœ í™•ì¸ API (ì¤‘ìš”!)
router.get('/transcribe/status/:jobId', (req, res) => {
  try {
    const { jobId } = req.params;
    const job = transcriptionJobs.get(jobId);

    if (!job) {
      return res.status(404).json({ 
        error: 'ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        jobId,
        code: 'JOB_NOT_FOUND'
      });
    }

    const response = {
      jobId: job.id,
      status: job.status,
      originalFilename: job.originalFilename,
      fileSize: job.fileSize,
      createdAt: job.createdAt,
      startedAt: job.startedAt,
      completedAt: job.completedAt
    };

    if (job.status === JobStatus.COMPLETED) {
      response.transcript = job.transcript;
    } else if (job.status === JobStatus.FAILED) {
      response.error = job.error;
    } else if (job.status === JobStatus.PROCESSING) {
      // ì§„í–‰ë¥  ê³„ì‚° (ì„ì‹œ)
      const progress = job.startedAt ? Math.min(0.9, (Date.now() - job.startedAt) / 30000) : 0;
      response.progress = progress;
    }

    res.json(response);

  } catch (error) {
    console.error('âŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨:', error);
    res.status(500).json({ error: 'ìƒíƒœ í™•ì¸ ì‹¤íŒ¨' });
  }
});

// ì‹œìŠ¤í…œ ì§„ë‹¨
router.get('/diagnose', async (req, res) => {
  try {
    const whisperInstalled = await checkWhisperInstallation();
    const activeJobs = Array.from(transcriptionJobs.values()).filter(job => 
      job.status === JobStatus.PROCESSING || job.status === JobStatus.PENDING
    ).length;

    res.json({
      status: 'OK',
      message: 'ë¶„ì‚° STT ì„œë¹„ìŠ¤ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.',
      timestamp: new Date().toISOString(),
      whisperInstalled,
      method: whisperInstalled ? 'Distributed Processing' : 'Dummy Response',
      activeJobs,
      recommendation: whisperInstalled ? null : 'pip3 install openai-whisper ëª…ë ¹ì–´ë¡œ Whisperë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.'
    });

  } catch (error) {
    console.error('âŒ ì§„ë‹¨ ì‹¤íŒ¨:', error);
    res.status(500).json({ error: 'ì§„ë‹¨ ì‹¤íŒ¨' });
  }
});

// í—¬ìŠ¤ ì²´í¬
router.get('/health', (req, res) => {
  res.json({
    status: 'OK',
    timestamp: new Date().toISOString(),
    uptime: process.uptime()
  });
});

// âœ… 30ë¶„ ëŒ€ì‘: ì›Œì»¤ ìƒíƒœ ë° í ëª¨ë‹ˆí„°ë§ API ì¶”ê°€
router.get('/workers/status', async (req, res) => {
  try {
    const transcriptionQueue = require('../services/transcription-queue');
    
    const waiting = await transcriptionQueue.getWaiting();
    const active = await transcriptionQueue.getActive();
    const completed = await transcriptionQueue.getCompleted();
    const failed = await transcriptionQueue.getFailed();
    
    // í™œì„± ì‘ì—…ë“¤ì˜ ìƒì„¸ ì •ë³´
    const activeDetails = active.map(job => ({
      id: job.id,
      jobId: job.data.jobId,
      chunkIndex: job.data.chunkIndex,
      totalChunks: job.data.totalChunks,
      language: job.data.language,
      progress: job.progress(),
      startedAt: job.processedOn,
      worker: job.opts.worker || 'unknown'
    }));
    
    // ì‹¤íŒ¨í•œ ì‘ì—…ë“¤ì˜ ìƒì„¸ ì •ë³´
    const failedDetails = failed.map(job => ({
      id: job.id,
      jobId: job.data.jobId,
      chunkIndex: job.data.chunkIndex,
      error: job.failedReason,
      attempts: job.attemptsMade,
      failedAt: job.failedOn
    }));
    
    res.json({
      timestamp: new Date().toISOString(),
      queue: {
        waiting: waiting.length,
        active: active.length,
        completed: completed.length,
        failed: failed.length
      },
      activeJobs: activeDetails,
      failedJobs: failedDetails,
      systemInfo: {
        containerName: process.env.CONTAINER_NAME || 'unknown',
        workerMode: process.env.WORKER_MODE || 'unknown',
        maxConcurrency: process.env.MAX_CONCURRENT_CHUNKS || 'unknown',
        queueProcessing: process.env.QUEUE_PROCESSING !== 'false'
      }
    });
    
  } catch (error) {
    console.error('âŒ ì›Œì»¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨:', error);
    res.status(500).json({ error: 'ì›Œì»¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨' });
  }
});

// âœ… 30ë¶„ ëŒ€ì‘: íŠ¹ì • ì‘ì—…ì˜ ìƒì„¸ ì§„í–‰ ìƒí™© API
router.get('/transcribe/:jobId/detailed-status', async (req, res) => {
  try {
    const { jobId } = req.params;
    const job = transcriptionJobs.get(jobId);

    if (!job) {
      return res.status(404).json({ 
        error: 'ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        jobId
      });
    }

    // Redisì—ì„œ ì‹¤ì‹œê°„ ì²­í¬ ìƒíƒœ í™•ì¸
    const redisClient = redis.createClient({
      url: 'redis://sayit-redis-m2:6379'
    });
    
    await redisClient.connect();
    
    const completedKeys = await redisClient.keys(`completed:${jobId}:chunk:*`);
    const failedKeys = await redisClient.keys(`failed:${jobId}:chunk:*`);
    
    const chunkStatus = [];
    const expectedChunks = job.expectedChunks || estimateChunkCount(job.fileSize);
    
    // ê° ì²­í¬ë³„ ìƒíƒœ í™•ì¸
    for (let i = 0; i < expectedChunks; i++) {
      const completedKey = `completed:${jobId}:chunk:${i}`;
      const failedKey = `failed:${jobId}:chunk:${i}`;
      
      if (completedKeys.some(key => key === completedKey)) {
        const data = JSON.parse(await redisClient.get(completedKey));
        chunkStatus.push({
          chunkIndex: i,
          status: 'completed',
          processedBy: data.processedBy,
          completedAt: data.timestamp
        });
      } else if (failedKeys.some(key => key === failedKey)) {
        const data = JSON.parse(await redisClient.get(failedKey));
        chunkStatus.push({
          chunkIndex: i,
          status: 'failed',
          failedBy: data.failedBy,
          error: data.errorMessage,
          failedAt: data.timestamp
        });
      } else {
        chunkStatus.push({
          chunkIndex: i,
          status: 'pending'
        });
      }
    }
    
    await redisClient.quit();

    const response = {
      jobId: job.id,
      status: job.status,
      originalFilename: job.originalFilename,
      fileSize: job.fileSize,
      expectedChunks: expectedChunks,
      completedChunks: chunkStatus.filter(c => c.status === 'completed').length,
      failedChunks: chunkStatus.filter(c => c.status === 'failed').length,
      pendingChunks: chunkStatus.filter(c => c.status === 'pending').length,
      chunkDetails: chunkStatus,
      createdAt: job.createdAt,
      startedAt: job.startedAt,
      completedAt: job.completedAt,
      processingTime: job.completedAt ? job.completedAt - job.createdAt : Date.now() - job.createdAt
    };

    if (job.status === JobStatus.COMPLETED) {
      response.transcript = job.transcript;
      response.successRate = job.successRate;
    } else if (job.status === JobStatus.FAILED) {
      response.error = job.error;
    }

    res.json(response);

  } catch (error) {
    console.error('âŒ ìƒì„¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨:', error);
    res.status(500).json({ error: 'ìƒì„¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨' });
  }
});




// âœ… ì •ê¸°ì  íŒŒì¼ ì •ë¦¬ (1ì‹œê°„ë§ˆë‹¤)
setInterval(async () => {
  try {
    console.log('ğŸ§¹ [Direct-Backend] ì •ê¸° íŒŒì¼ ì •ë¦¬ ì‹œì‘...');
    
    const now = Date.now();
    const oneHourAgo = now - (60 * 60 * 1000);
    
    // 1ì‹œê°„ ì´ìƒ ëœ temp ë””ë ‰í† ë¦¬ ì •ë¦¬
    const tempBaseDir = '/app/temp';
    const tempDirs = await fs.readdir(tempBaseDir).catch(() => []);
    
    for (const dir of tempDirs) {
      if (dir.startsWith('job_')) {
        const dirPath = path.join(tempBaseDir, dir);
        const stats = await fs.stat(dirPath).catch(() => null);
        
        if (stats && stats.mtime.getTime() < oneHourAgo) {
          console.log(`ğŸ§¹ [Direct-Backend] ì˜¤ë˜ëœ temp ë””ë ‰í† ë¦¬ ì •ë¦¬: ${dir}`);
          await cleanupTempFiles(dirPath);
        }
      }
    }
    
    // 1ì‹œê°„ ì´ìƒ ëœ ì—…ë¡œë“œ íŒŒì¼ ì •ë¦¬
    const uploadDir = '/app/uploads';
    const uploadFiles = await fs.readdir(uploadDir).catch(() => []);
    
    for (const file of uploadFiles) {
      if (file.startsWith('audio-')) {
        const filePath = path.join(uploadDir, file);
        const stats = await fs.stat(filePath).catch(() => null);
        
        if (stats && stats.mtime.getTime() < oneHourAgo) {
          console.log(`ğŸ§¹ [Direct-Backend] ì˜¤ë˜ëœ ì—…ë¡œë“œ íŒŒì¼ ì •ë¦¬: ${file}`);
          await fs.unlink(filePath).catch(console.error);
        }
      }
    }
    
    console.log('âœ… [Direct-Backend] ì •ê¸° íŒŒì¼ ì •ë¦¬ ì™„ë£Œ');
    
  } catch (error) {
    console.error('âŒ [Direct-Backend] ì •ê¸° íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨:', error);
  }
}, 60 * 60 * 1000); // 1ì‹œê°„ë§ˆë‹¤

console.log('âœ… ì •ê¸° íŒŒì¼ ì •ë¦¬ ì‹œìŠ¤í…œ ì‹œì‘ (1ì‹œê°„ ê°„ê²©)');

module.exports = router;